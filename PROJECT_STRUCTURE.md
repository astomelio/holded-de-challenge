# Holded Data Engineering Challenge - Project Structure

## ğŸ“ Repository Organization

This repository implements a complete real-time data pipeline for processing Holded business events using modern data engineering practices.

### ğŸ—ï¸ Architecture Overview

```
Holded Events â†’ FastAPI â†’ Kafka â†’ Apache Beam â†’ Kafka â†’ MySQL
     â†“              â†“         â†“         â†“         â†“        â†“
  Raw Data    Bronze Layer  Processing Silver Layer  Gold Layer
```

### ğŸ“‚ Directory Structure

```
holded-de-challenge/
â”œâ”€â”€ api/                           # FastAPI Application
â”‚   â”œâ”€â”€ main.py                   # Main API with /collect endpoint
â”‚   â”œâ”€â”€ pyproject.toml           # Python dependencies
â”‚   â”œâ”€â”€ poetry.lock              # Locked dependencies
â”‚   â””â”€â”€ Dockerfile               # Container configuration
â”‚
â”œâ”€â”€ beam/                         # Apache Beam Processing
â”‚   â”œâ”€â”€ pipeline.py              # Main Beam pipeline
â”‚   â”œâ”€â”€ gold_sink.py             # MySQL sink for Gold layer
â”‚   â”œâ”€â”€ pyproject.toml           # Python dependencies
â”‚   â”œâ”€â”€ poetry.lock              # Locked dependencies
â”‚   â””â”€â”€ Dockerfile               # Container configuration
â”‚
â”œâ”€â”€ sql/                          # Database Schema
â”‚   â””â”€â”€ 001_create_events.sql    # MySQL table definitions
â”‚
â”œâ”€â”€ schemas/                      # Data Schemas
â”‚   â””â”€â”€ event.avsc               # Avro schema for events
â”‚
â”œâ”€â”€ scripts/                      # Configuration Scripts
â”‚   â”œâ”€â”€ create_topics.sh         # Kafka topics creation
â”‚   â”œâ”€â”€ register_schema.sh       # Schema registry setup
â”‚   â”œâ”€â”€ start.sh                 # Complete system startup
â”‚   â””â”€â”€ topics/
â”‚       â””â”€â”€ main-topics          # Topic configurations
â”‚
â”œâ”€â”€ test-data/                    # Test Data
â”‚   â””â”€â”€ de-sde-challenge/        # Original Holded test data
â”‚       â”œâ”€â”€ generator/
â”‚       â”‚   â”œâ”€â”€ events.json      # Real Holded events
â”‚       â”‚   â””â”€â”€ generator.py     # Event generator
â”‚       â”œâ”€â”€ api/                 # Original API structure
â”‚       â”œâ”€â”€ beam/                # Original Beam structure
â”‚       â””â”€â”€ schemas/             # Original schemas
â”‚
â”œâ”€â”€ docker-compose.yml           # Complete infrastructure
â”œâ”€â”€ send_holded_events.py        # Test event sender
â”œâ”€â”€ test_integration.py          # Integration tests
â”œâ”€â”€ README.md                    # Main documentation
â””â”€â”€ PROJECT_STRUCTURE.md         # This file
```

## ğŸ”§ Component Details

### ğŸŒ API Layer (`/api/`)
- **Purpose**: Receives Holded events in their original format
- **Technology**: FastAPI, Pydantic, Kafka
- **Key Features**:
  - `/collect` endpoint for Holded events
  - Data validation with Pydantic
  - Kafka producer for streaming
  - Health checks and monitoring
  - Auto-generated API documentation

### âš¡ Processing Layer (`/beam/`)
- **Purpose**: Processes events with validation, enrichment, and deduplication
- **Technology**: Apache Beam, Kafka, Python
- **Key Features**:
  - Event validation and filtering
  - Data deduplication
  - Business context classification
  - Data quality scoring
  - Dead letter queue handling

### ğŸ—„ï¸ Storage Layer (`/sql/`)
- **Purpose**: Stores processed events for analytics
- **Technology**: MySQL 8.0
- **Key Features**:
  - Optimized table structure
  - Indexes for performance
  - JSON metadata storage
  - Aggregation tables
  - Dead letter queue table

### ğŸ³ Infrastructure (`/scripts/`, `docker-compose.yml`)
- **Purpose**: Complete system orchestration
- **Technology**: Docker, Docker Compose, Kafka, Zookeeper
- **Key Features**:
  - One-command startup
  - Kafka topic management
  - Schema registry setup
  - Database initialization

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop
- Python 3.13+
- Poetry

### Complete System Startup
```bash
# Start everything
./scripts/start.sh

# Or manually
docker-compose up -d
./scripts/create_topics.sh
./scripts/register_schema.sh
```

### Individual Component Startup
```bash
# API
cd api && poetry install && poetry run python main.py

# Beam Pipeline
cd beam && poetry install && poetry run python pipeline.py

# Gold Sink
cd beam && poetry run python gold_sink.py
```

## ğŸ“Š Data Flow

1. **Event Ingestion**: Holded events â†’ FastAPI `/collect`
2. **Bronze Layer**: Raw events â†’ Kafka `events.raw`
3. **Processing**: Apache Beam validates, enriches, deduplicates
4. **Silver Layer**: Processed events â†’ Kafka `events.silver`
5. **Gold Layer**: Final events â†’ MySQL database
6. **Analytics**: Aggregated data available for reporting

## ğŸ” Key Files Explained

### `api/main.py`
- FastAPI application with `/collect` endpoint
- Handles Holded events in original format
- Publishes to Kafka `events.raw` topic

### `beam/pipeline.py`
- Apache Beam streaming pipeline
- Processes events from `events.raw`
- Publishes to `events.silver`

### `beam/gold_sink.py`
- Kafka consumer for `events.silver`
- Writes to MySQL database
- Handles aggregations and summaries

### `sql/001_create_events.sql`
- MySQL table definitions
- Optimized indexes
- JSON metadata support

### `docker-compose.yml`
- Complete infrastructure definition
- Kafka, Zookeeper, MySQL, Schema Registry
- API and Beam services

## ğŸ§ª Testing

### Send Test Events
```bash
python send_holded_events.py
```

### Verify System Health
```bash
curl http://localhost:8000/health
curl http://localhost:8000/docs
```

### Check Database
```bash
docker exec mysql mysql -u holded -pholded123 holded_events -e "SELECT COUNT(*) FROM events;"
```

## ğŸ“ˆ Monitoring

- **API Health**: `http://localhost:8000/health`
- **API Docs**: `http://localhost:8000/docs`
- **Kafka Topics**: Use Kafka tools
- **Database**: Connect to MySQL on localhost:3306

## ğŸ”’ Security & Best Practices

- Input validation on all endpoints
- Data sanitization in pipeline
- Error handling with dead letter queue
- Audit logging for compliance
- Containerized deployment
- Environment variable configuration

---

**Status**: âœ… Production Ready
**Last Updated**: January 2025
**Version**: 1.0.0
